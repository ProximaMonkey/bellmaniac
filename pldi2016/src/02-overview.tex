\section{Overview}
\label{overview}

Most readers are likely familiar with the Dynamic Programming (DP) technique of Richard Bellman~\cite{03/Bellman:DP} to construct an optimal solution to a problem by combining together optimal solutions to many overlapping sub-problems. The key to DP is to exploit the overlap in order to explore otherwise exponential-sized problem spaces in polynomial time. Dynamic programs are usually described through recurrence relations that specify how the cells in a DP table must be filled using solutions already computed for other cells, but recent research has shown that it is possible to achieve order-of-magnitude performance improvements over this standard implementation approach by developing \emph{divide-and-conquer}  implementation strategies that recursively
partition the space of subproblems into smaller subspaces (see, e.g., \cite{IPDPS15/Tithi}).   For example, Tithi \etal{} have shown that for classical DP problems such as Floyd-Warshall, the parallel divide-and-conquer implementation is  8x faster  across a range of problem sizes compared with a parallel tiled implementation thanks to the better temporal locality and the additional optimization opportunities exposed by partitioning~\cite{IPDPS15/Tithi}. These performance differences matter because  DP is central to many important domains ranging from logistics to computational biology; as an illustrative example, a recent textbook \cite{DurbinEdKr98} on biological sequence analysis lists 11 applications of DP in bioinformatics just in its introductory chapter, with many more in chapters that follow.


%To set up the premises, we are going to explain how an algorithms expert---we will call him Richard---would go about designing such an implementation by hand.
%We will then show how he will be able to do it more easily using Bellmania.

To illustrate the key concepts undelying Bellmania, we will walk through the first
few steps that an algorithms expert --- whom we will call Richard --- would follow to
generate a provably correct divide-and-conquer implementation of a DP algorithm.
As a motivating example, we consider the Simplified Arbiter problem.
Two processes $x$ and $y$ must be scheduled to run $n$ and $m$ seconds,
respectively, on a single processor, using one-second slots.
Execution starts at $t=0$. The cost for scheduling the slots $[a..b)$ of $x$ after
having scheduled slots $[0..c)$ of $y$
is given by $\xw{abc}$, and the cost for schedulting the slots $[a..b)$ of $y$
after scheduling $[0..c)$ of $x$ is given by $\yw{abc}$.

\begin{figure}[b]
\begin{tabular}{@{\hspace{-1pt}}r@{~}l@{}}
\begin{tikzpicture}[x=4.1mm,y=4.1mm,baseline=(center), remember picture]
  \coordinate(center) at (3,3);
  \draw[step=1] (0,0) grid (6,6);
  \draw[ultra thick] (4,2) rectangle +(1,1);
  %\node(Gij) at (4.5,2.5) {\tiny $\scriptscriptstyle\langle i,j\rangle$};
  \node[circle,fill=BrickRed,inner sep=0,minimum size=1mm](Gij) at (4.5,2.5) {};
  \fill[black,opacity=0.1] (0,5) rectangle (6,6);
  \fill[black,opacity=0.1] (0,0) rectangle (1,5);
  \fill[blue,opacity=0.2] (0,2) rectangle (4,3);
  \fill[blue,opacity=0.2] (4,3) rectangle (5,6);
  \node[anchor=south east](G) at (0,6) {\small$G$};
  \draw[->] (G.east) -- +(1.5,0) node[anchor=west] {\small $j$};
  \draw[->] (G.south) -- +(0,-1.5) node[anchor=north] {\small $i$};
\end{tikzpicture}
&
\small
$
\begin{array}{l@{}}
	\tikz[overlay, remember picture]{\draw[BrickRed] (0,0) -- (Gij);}
	G_{ij} ~=~ \\
	~
	\begin{cases}
		0                        & i=j=0 \\
		\yw{0j0}                  & i=0, j>0 \\
		\xw{0i0}                 & i>0, j=0 \\
		\begin{array}{@{}l@{\hspace{-1pt}}l@{\hspace{-4pt}}}
		  \min\langle & \underset{0\leq q<j}\min ~ G_{iq} + \yw{qji},  \\
		              & \underset{0\leq p<i}\min ~ G_{pj} + \xw{pij}~\rangle
		\end{array}              & i,j>0
	\end{cases}
\end{array}
$
\end{tabular}
\vspace{5pt}
\caption{Recurrence equation and cell-level dependencies.}
\label{overview:arbiter spec}
\end{figure}


The optimal cost for scheduling the first $i$ slots of $x$ and the first $j$ slots
of $y$ is given by the recurrence $G_{ij}$ in \Cref{overview:arbiter spec}. When $i$ is zero, it means that
only $y$ has been scheduled, so the cost is $\yw{0j0}$, and similarly when $j$ is zero, 
the cost is $\xw{0i0}$. When $i$ and $j$ are both positive, there are two options:
either the schedule ends with an allocation to $x$, 
where slots $[p..i)$ of $x$ were scheduled at $t=p+j$, and the cost is 
$G_{pj} + \xw{pij}$; or it ends with an allocation to $y$, where
slots $[q..j)$ of $y$ were scheduled at $t=i+q$, and the cost is $G_{iq} + \yw{qji}$.
The minimum over all respective $p<i$ and $q<j$ is taken.
Eventually, the optimal cost of the entire schedule is given by $G_{nm}$.

\begin{paragraph}{Iterative Algorithm.}
Using a standard dynamic programming method, our algorithm expert Richard would compute this recurrence
with an iterative program by understanding the dependency pattern:
to compute the $\min\langle\cdots\rangle$ expression in \Cref{overview:arbiter spec} and find the optimal
values for $p$ and $q$, the algorithm needs information from all cells above and to the left of $G_{ij}$.
In particular, each value $G_{ij}$ is computed from other values $G_{i'j'}$ with lower
indexes, $i'<i$, ~$j'<j$. 
Therefore, considering $G$ as a two-dimensional array, it can be filled in a single pass from left to right and from top
to bottom, as shown in \Cref{overview:iterative}.
\end{paragraph}

\newcommand\FORLINE[1]{\State\algorithmicfor~{#1} \algorithmicdo~}
\newcommand\Head[1]{\Comment{ {\it #1} ~~}}

\begin{algorithm}
\renewcommand\arraystretch{1.3}
\begin{algorithmic}
  \State $G_{00} := 0$    \Head{Initialize}
  \FORLINE{$i=1..n$}  $G_{i0} := \xw{0i0}$
  \FORLINE{$j=1..m$}  $G_{0j} := \yw{0j0}$  
  \For{$i=1..n$}          \Head{Compute}
    \For{$j=1..m$}
      \State $G_{ij} :=
        \begin{array}[t]{@{}l@{~}l} 
          \min\langle & \underset{0\leq q<j}\min ~ G_{iq} + \yw{qji}, \\
                      & \underset{0\leq p<i}\min ~ G_{pj} + \xw{pij}~\rangle \\         
        \end{array}$
    \EndFor
  \EndFor
\end{algorithmic}
\caption{\label{overview:iterative}
   Iterative Simplified Arbiter}
\end{algorithm}



\newcommand\qbox[1]{\fbox{\rm\scriptsize#1}}
\newcommand\tinyqbox[1]{\hspace{.5pt}\tikz \node[draw,inner sep=1.5pt] {$\scriptscriptstyle #1$};}

\newcommand\plusoneocd{\raisebox{.5pt}{$\scriptstyle+1$}}

\algrenewtext{Procedure}{\hspace{-3mm}{\bf procedure}~}  % hach to make proc header slighly less indented

\begin{paragraph}{Divide-and-Conquer Algorithm.}

\begin{figure}
\centering
\begin{tabular}{c@{\hspace{.5in}}c}
\begin{tikzpicture}[baseline=(base), q/.style={font=\relsize{1.3}}]
  \draw (0,0) grid (2,2);
  \node[q] at (.5,1.5) {1};   \node[q] at (1.5,1.5) {2};
  \node[q] at (.5, .5) {3};   \node[q] at (1.5, .5) {4};
  \node[above left] at (0,2) {$0$};
  \node[above] at (1,2) {$\frac{m}{2}$};
  \node[above] at (2,2) {$m$};
  \node(base)[left] at (0,1) {$\frac{n}{2}$};
  \node[left] at (0,0) {$n$};
  \node(J0)[above] at (.5,2.5) {$J_0$};
  \node(J1)[above] at (1.5,2.5) {$J_1$};
  \node(I0)[left] at (-.5,.5) {$I_0$};
  \node(I1)[left] at (-.5,1.5) {$I_1$};
  \coordinate(0) at (0,0);
  \coordinate(sw) at (0,0);
  \coordinate(ne) at (2,2);
  \draw (J0.north -| sw) -- node[above] {$J$} ++(ne |- 0);
  \draw (I0.west |- sw) -- node[left] {$I$} ++(ne -| 0);
\end{tikzpicture}
& 
$\begin{array}{l}\qbox1 \rightsquigarrow \qbox2 \\ 
\qbox1 \rightsquigarrow \qbox3 \\ \qbox2\rightsquigarrow \qbox4 \\ \qbox3 \rightsquigarrow \qbox4\end{array}$
\end{tabular}
\vspace{5pt}
\caption{\label{overview:quadrants}
  Dividing a two-dimensional array into quadrants; the dependencies are shown on the right.}
\end{figure}

Divide-and-conquer is a common algorithm development pattern (\cite{09/CLRS}, chapter 4) that has recently
been applied to DP (\cite{SODA06/Chowdhury,SPAA08/Chowdhury,TOCS10/Chowdhury,TCBB10/Chowdhury}).
This approach has the benefit of yielding cache-oblivious implementations by
increasing memory locality while preserving parallelism. With divide-and-conquer,
the DP table is partitioned into regions, and each region is expressed as a sub-problem
to be solved.

We will now describe how Richard approaches the running example using Bellmania.
He would like to partition the two-di\-men\-sio\-nal array $G$ into
quadrants, as illustrated in \Cref{overview:quadrants}.
In Bellmania, this is accomplished by applying the {\sf Slice} tactic,
illustrated graphically at the top of \Cref{overview:slice-stratify-synth}.
{\em Tactics} are transformation steps that manipulate the program,
and represent a high-level refinement concept.
The partitions are labeled $I_0,I_1$ and $J_0,J_1$ for row index ranges and column index ranges,
respectively.
Slicing gives the analog of the specification in \Cref{overview:logical-slice-stratify}({\it i}).
The expression inside $\min\langle\cdots\rangle$ is shortened for space,
but it is the same as in \Cref{overview:iterative}.

Following the same reasoning as in the iterative case, computing \qbox1
does not depend on any of the other computations. Richard applies the
{\sf Stratify} tactic, which encodes exactly this intuition: it separates
an independent computation step as a separate loop.
This is equivalent to rewriting the specification as in \Cref{overview:logical-slice-stratify}({\it ii}):
the first computation is given a special name $G^{\tinyqbox1}$, then the following
computations read data either from $G^{\tinyqbox1}$ (when the indices are in \qbox1)
or from $G$ (otherwise), which is denoted by $G^{\tinyqbox1}\!/G$. The ``$/\,$'' operator
is part of the Bellmania language and will be defined formally in \Cref{lang}.
Bellmania checks the data dependencies and verifies that the transformation
is sound.

Repeating {\sf Stratify} would result in a four-step computation
as seen in \Cref{overview:chain}, from which Richard can obtain the program in \Cref{overview:breakdown}
(only the first two steps are shown, remaining steps are analogous).
This already gives some performance, since the compututations \qbox2 and \qbox3
can now run in parallel. However, this is not what Richard wants; so he
changes the development of this procedure, which he calls ``A'', to produce
a recursive divide-and-conquer algorithm.
\end{paragraph}


\begin{figure}
\[\renewcommand\arraystretch{1.3}
  \begin{array}{@{}l@{}}
    \textsf{Slice} \quad i:\langle I_0|I_1\rangle \quad j:\langle J_0|J_1\rangle \hfill (i)\\
    ~\forall i,j\in\qbox1.~ G_{ij} = \min \langle\cdots G_{iq} \cdots G_{pj} \cdots \rangle \\
    ~\forall i,j\in\qbox2.~ G_{ij} = \min \langle\cdots G_{iq} \cdots G_{pj} \cdots \rangle \\
    ~\forall i,j\in\qbox3.~ G_{ij} = \min \langle\cdots G_{iq} \cdots G_{pj} \cdots \rangle \\
    ~\forall i,j\in\qbox4.~ G_{ij} = \min \langle\cdots G_{iq} \cdots G_{pj} \cdots \rangle \\
    %
    \textsf{Stratify} ~ \qbox1 \hfill (ii)\\
    %
    ~\forall i,j\in\qbox1.~ G^{\tinyqbox1}_{ij} = \min \langle\cdots G^{\tinyqbox1}_{iq} \cdots G^{\tinyqbox1}_{pj} \cdots \rangle \\
    ~\forall i,j\in\qbox2.~ G_{ij} = \min \langle\cdots (G^{\tinyqbox1}\!/G)_{iq} \cdots (G/G^{\tinyqbox1})_{pj} \cdots \rangle \\
    ~\forall i,j\in\qbox3.~ G_{ij} = \min \langle\cdots (G/G^{\tinyqbox1})_{iq} \cdots (G/G^{\tinyqbox1})_{pj} \cdots \rangle \\
    ~\forall i,j\in\qbox4.~ G_{ij} = \min \langle\cdots (G/G^{\tinyqbox1})_{iq} \cdots (G/G^{\tinyqbox1})_{pj} \cdots \rangle
  \end{array}
\]
\caption{\label{overview:logical-slice-stratify}
  The first two steps in the development, represented as logical specifications.}
\end{figure}


\newcommand\steparrowwidth{3mm}
\newcommand\steparrow{\includegraphics[width=\steparrowwidth]{img/arrow}}

\begin{figure}
\centering
\ifarmando
\bigskip(missing figure)\bigskip
\else
\input{gfx/overview-chain}
\fi
\caption[caption]{\label{overview:chain}
  Stratified computation for Simplified Arbiter. \\[.2em]
  The array is initially empty except for the hatched area that is
  filled by {\it Initialize}.
  Shaded areas indicate the region that is read at each step.
  The arrows point at the quadrant that is written to. }
\end{figure}

\newcommand\applytactic[1]{{\tt >} \sf #1}
\newcommand\applytacticnode[1]{\node[right,align=left] at (3,1) {\applytactic{#1}}}


\begin{algorithm}
\renewcommand\arraystretch{1.3}
\begin{algorithmic}
\Procedure{A{\larger{[}}$G${\larger{]}}}{}\EndProcedure
  \For{$i=1..\frac{n}{2}$}    \Head{Compute \qbox1}
    \For{$j=1..\frac{m}{2}$} 
      \State \hspace{-.5cm}$G_{ij} :=
        \begin{array}{@{}l@{~}l} 
          \min\langle & \underset{0\leq q<j}\min ~ G_{iq} + \yw{qji}, 
                        \underset{0\leq p<i}\min ~ G_{pj} + \xw{pij}~\rangle \\         
        \end{array}$
    \EndFor
  \EndFor
  \For{$i=1..\frac{n}{2}$}    \Head{Compute \qbox2}
    \For{$j=\frac{m}{2}\plusoneocd..m$}
      \State \hspace{-.5cm}$G_{ij} :=
        \begin{array}[t]{@{}l@{~}l} 
          \min\langle & \underset{0\leq q<j}\min ~ G_{iq} + \yw{qji}, 
                        \underset{0\leq p<i}\min ~ G_{pj} + \xw{pij}~\rangle \\         
        \end{array}$
    \EndFor
  \EndFor
  \State $\vdots$ \Head{Compute \qbox3}
\end{algorithmic}
\caption{\label{overview:breakdown}
   Simplified Arbiter --- Sliced and Stratified}
\end{algorithm}

\begin{algorithm}
\renewcommand\arraystretch{1.3}
\begin{algorithmic}
\Procedure{A{\larger{[}}$G${\larger{]}}}{}\EndProcedure
  \State A\big[$G_{(0..\frac{n}{2})(0..\frac{m}{2})}$\big] \Head{Compute \qbox1}
  \For{$i=1..\frac{n}{2}$}    \Head{Compute \qbox2}
    \For{$j=\frac{m}{2}\plusoneocd..m$}
      \State $G_{ij} :=
        \begin{array}[t]{@{}l@{~}l} 
          \min\langle & \underset{0\leq q<\frac{m}{2}}\min ~ G_{iq} + \yw{qji}~\rangle \\         
        \end{array}$
          \Comment{(left)}
    \EndFor
  \EndFor
  \For{$i=1..\frac{n}{2}$}
    \For{$j=\frac{m}{2}\plusoneocd..m$}
      \State $G_{ij} :=
        \begin{array}[t]{@{}l@{~}l} 
          \min\langle G_{ij}, & \underset{\frac{m}{2}\leq q<j}\min ~ G_{iq} + \yw{qji}, \\
                      & \underset{0\leq p<i}\min ~ G_{pj} + \xw{pij}~\rangle \\         
        \end{array}$
          \Comment{(right)}
    \EndFor
  \EndFor
  \State $\vdots$
\end{algorithmic}
\caption{\label{overview:further-breakdown}
   Simplified Arbiter --- Sliced Even More}
\end{algorithm}


\newbox\primebox
\setbox\primebox\hbox{$'$}
\newbox\doubleprimebox
\setbox\doubleprimebox\hbox{$''$}

\newcommand\primeocd[1]{\hspace{\wd\primebox}#1\usebox\primebox}
\newcommand\doubleprimeocd[1]{\hspace{\wd\doubleprimebox}#1\usebox\doubleprimebox}

\begin{figure}
\centering
\ifarmando
\bigskip(missing figure)\bigskip
\else
\input{gfx/overview-slice-stratify-synth}
\vspace{-2mm}
\fi
\caption[caption]{\label{overview:slice-stratify-synth}
  Overview of tactic semantics in Bellmania. }
\end{figure}


\medskip
At this point, Richard notices that {\it Compute \qbox1} is just a smaller version of
the original {\it Compute}; so following {\sf Stratify} \qbox1, he invokes {\sf Synth}, which automatically
synthesizes a recursive call A\big[$G_{(0..\frac{n}{2})(0..\frac{m}{2})}$\big]
(presented using abstract index ranges as $A^{I_0J_0}$).

The other steps require some further algebraic manipulation.
Observe that the computation of \qbox2 is {\bf not} equivalent to
A\big[$G_{(0..\frac{n}{2})(\frac{m}{2}..m)}$], 
because when $\frac{m}{2} \leq j < m$, the range of $0\leq q < j$ leads to
some of the access $G_{iq}$ lying outside of \qbox2.

Richard addressed this problem by splitting the range of $q$ using the {\sf Slice}
tactic again, effectively breaking the original $\min\langle\cdots\rangle$ into two:
one where $0\leq q < \frac{m}{2}$,
and one where $\frac{m}{2}\leq q < j$. 
He uses {\sf Stratify} to organize the loops in the program such that both 
loops write to the same area, namely \qbox2, where the second loop reads data
written by the first loop, as shown in \Cref{overview:further-breakdown}.
It is important to notice that the first loop only reads from \qbox1, 
while the second loop only reads from \qbox2.

The computation of \qbox2:(right) is now a true copy of A,
with sub-matrix $G_{(0..\frac{n}{2})(\frac{m}{2}..m)}$ (with the small caveat,
that A has to be changed to include the term $G_{ij}$ in the $\min\langle~\rangle$ expression).
Again, Bellmania synthesizes the sub-call and proves the equivalence.
Running {\sf Synth} on \qbox2:(left) will reveal that it is a new computation,
to which Richard gives the name ``B''. 

After repeating
the same reasoning steps to \qbox3 and \qbox4,
Richard finally has the version in \Cref{overview:recursive-A}.
The base case (when $G$ is small) is added automatically by the Bellmania compiler.
The specific size bound needs to be tuned for performance.\footnote{The auto-tuning step is not implemented in the current version.}


\begin{algorithm}
\renewcommand\arraystretch{1.3}
\begin{algorithmic}
\Procedure{A{\larger{[}}$G${\larger{]}}}{}\EndProcedure
  \If{$G$ {\it is very small}} {\it run iterative version}
  \Else
  \State A\big[$G_{(0..\frac{n}{2})(0..\frac{m}{2})}$\big] \Head{Compute \qbox1}
  \State B\big[$G_{(0..\frac{n}{2})(0..\frac{m}{2})}, 
                G_{(0..\frac{n}{2})(\frac{m}{2}..m)}$\big]    \Head{Compute \qbox2}
  \State A\big[$G_{(0..\frac{n}{2})(\frac{m}{2}..m)}$\big]
  \State C\big[$G_{(0..\frac{n}{2})(0..\frac{m}{2})}, 
                G_{(\frac{n}{2}..n)(0..\frac{m}{2})}$\big]    \Head{Compute \qbox3}
  \State A\big[$G_{(\frac{n}{2}..n)(0..\frac{m}{2})}$\big]
  \State B\big[$G_{(\frac{n}{2}..n)(0..\frac{m}{2})}, 
                G_{(\frac{n}{2}..n)(\frac{m}{2}..m)}$\big]    \Head{Compute \qbox4}
  \State C\big[$G_{(0..\frac{n}{2})(\frac{m}{2}..m)}, 
                G_{(\frac{n}{2}..n)(\frac{m}{2}..m)}$\big]
  \State A\big[$G_{(0..\frac{n}{2})(\frac{m}{2}..m)}$\big]
  \EndIf
\end{algorithmic}
\caption{\label{overview:recursive-A}
   Simplified Arbiter --- Recursive Version}
\end{algorithm}

Richard must then use the same strategy to further break down and
transform the computations of B and C, each into four recursive sub-computations, 
further improving the locality of the resulting algorithm.
Eventually, through this kind of transformations, he can succeed in breaking the computation of $G$ into recursive sub-computations leading to a true divide-and-conquer algorithm. 

As is well illustrated by the example, this line of reasoning can get quite complicated for most dynamic programming algorithms, 
and producing a correct divide-and-conquer algorithm for a given dynamic programming problem is considered quite difficult even by the researchers who originally pioneered the technique. 
Fortunately, the reasoning can be mechanized in Bellmania, which allows
Richard and other algorithm designers to produce an implementation of this algorithm
as well as a {\bf machine-checked proof} of correctness
through a series of high-level tactic application.

Overall, it took Richard only about 10 steps to construct \Cref{overview:recursive-A},
and a total of 26 steps to construct all three steps of the Simplified Arbiter,
comprising an implementation that is 10$\times$ faster than a parallel
\Cref{overview:iterative} generated by a state-of-the-art parallelizing compiler.
The user is greatly assisted by tactics like {\sf Synth}, that carry out the monotonic
and error-prone task of choosing the right parameters for each recursive call; also,
mistakes are identified early in the development thanks to automatic verification,
saving hours of debugging later on.

Once a divide-and-conquer algorithm is found, generating an optimal implementation still requires some additional work, such as finding the right point at which to switch to an iterative algorithm to leverage SIMD parallelism as well as low-level tuning and compiler optimization;
these steps are performed by more traditional compiler optimization techniques
as discussed in \Cref{codegen}.

In the following sections, we describe the different components of Bellmania. 
The system utilizes \newterm{solver-aided tactics} to manipulate a given specification
and generate provably correct pseudo-code; 
this approach is demonstrated by engineering specialized tactics for the domain of divide-and-conquer DP.
